# Classification-of-an-audio-dataset-of-spoken-digits-MNIST
Developed a machine learning pipeline to classify spoken digits based on audio recordings using time-domain and frequency-domain feature extraction techniques, including Zero-Crossing Rate (ZCR), signal energy, duration, Mel Spectrograms, and MFCCs using NumPy and Librosa.
