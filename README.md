# Classification-of-an-audio-dataset-of-spoken-digits-MNIST

Built a machine learning pipeline to classify spoken digits from audio recordings using extracted signal features.

Utilized the Free Spoken Digit Dataset (FSDD) (licensed under Creative Commons Attribution-ShareAlike 4.0 International) for training and evaluation.
http://github.com/Jakobovski/free-spoken-digit-dataset

Engineered time-domain and frequency-domain features, including Zero-Crossing Rate (ZCR), signal energy, duration, Mel Spectrograms, and MFCCs.

Trained and evaluated Support Vector Machine (SVM) models using cross-validation and hyperparameter tuning.

Achieved strong classification performance, especially with MFCC-based features; analyzed confusion matrices and visualized spectrograms to interpret misclassifications.
